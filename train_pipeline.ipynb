{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from radfusion import RadFusionCT\n",
    "import torch\n",
    "from torch import nn\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import f1_score, recall_score, precision_score, accuracy_score\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ct_embs = \"/home/nuren.zhaksylyk/Documents/HC701/project/PEFormer/data/ct/all_ct_out_embeds.pickle\"\n",
    "all_emr_embs = \"/home/nuren.zhaksylyk/Documents/HC701/project/PEFormer/data/ehr/all_emr_embs.pickle\"\n",
    "labels_csv = \"/home/nuren.zhaksylyk/Documents/HC701/project/PEFormer/data/ct/all_ct_labels_split.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1454 samples for train set.\n",
      "Loaded 193 samples for val set.\n",
      "Loaded 190 samples for test set.\n"
     ]
    }
   ],
   "source": [
    "dataset_train = RadFusionCT(pkl_ct_file=all_ct_embs, pkl_emr_file=all_emr_embs, csv_file=labels_csv, split='train')\n",
    "dataset_val = RadFusionCT(pkl_ct_file=all_ct_embs, pkl_emr_file=all_emr_embs, csv_file=labels_csv, split='val')\n",
    "dataset_test = RadFusionCT(pkl_ct_file=all_ct_embs, pkl_emr_file=all_emr_embs, csv_file=labels_csv, split='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1436\n",
      "torch.Size([110, 2048])\n",
      "torch.Size([110])\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "study_num, embeddings, mask, target = dataset_train[0]\n",
    "print(study_num)\n",
    "print(embeddings.shape)\n",
    "print(mask.shape)\n",
    "print(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AbsolutePositionalEncoder(nn.Module):\n",
    "    def __init__(self, emb_dim, max_position=111):\n",
    "        super(AbsolutePositionalEncoder, self).__init__()\n",
    "        self.position = torch.arange(max_position).unsqueeze(1)\n",
    "\n",
    "        self.positional_encoding = torch.zeros(1, max_position, emb_dim)\n",
    "\n",
    "        _2i = torch.arange(0, emb_dim, step=2).float()\n",
    "\n",
    "        # PE(pos, 2i) = sin(pos/10000^(2i/d_model))\n",
    "        self.positional_encoding[0, :, 0::2] = torch.sin(self.position / (10000 ** (_2i / emb_dim)))\n",
    "\n",
    "        # PE(pos, 2i+1) = cos(pos/10000^(2i/d_model))\n",
    "        self.positional_encoding[0, :, 1::2] = torch.cos(self.position / (10000 ** (_2i / emb_dim)))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # batch_size, input_len, embedding_dim\n",
    "        batch_size, seq_len, _ = x.size()\n",
    "\n",
    "        return self.positional_encoding[:batch_size, :seq_len, :]\n",
    "\n",
    "\n",
    "\n",
    "class PEFormer(nn.Module):\n",
    "    def __init__(self, \n",
    "                 max_num_emb=110, \n",
    "                 emb_dim = 2048, \n",
    "                 num_heads = 8,\n",
    "                 num_enc_layer = 6,\n",
    "                 num_dec_layer = 6,\n",
    "                 num_classes = 1,\n",
    "                 dim_feedforward = 2048):\n",
    "        super(PEFormer, self).__init__()\n",
    "\n",
    "        self.positional_encoder = AbsolutePositionalEncoder(emb_dim, max_position=max_num_emb+1)\n",
    "\n",
    "        self.cl_token = nn.Parameter(torch.randn(1, emb_dim))\n",
    "\n",
    "        self.transformer = nn.Transformer(d_model=emb_dim, nhead=num_heads, num_encoder_layers=num_enc_layer, num_decoder_layers=num_dec_layer, batch_first=True, dim_feedforward=dim_feedforward)\n",
    "\n",
    "        self.fc = nn.Linear(emb_dim, num_classes)\n",
    "    \n",
    "    def forward(self, x, mask):\n",
    "        batch_size, seq_len, emb_dim = x.size()\n",
    "\n",
    "        x = torch.cat([self.cl_token.expand(batch_size, -1, -1), x], dim=1)\n",
    "        pos_enc = self.positional_encoder(x).to(x.device)\n",
    "        x = x + pos_enc\n",
    "\n",
    "        #add False to the beginning of mask to account for CL token\n",
    "        mask = torch.cat([torch.tensor([[False]]).expand(batch_size, 1).to(mask.device), mask], dim=1)\n",
    "\n",
    "        x = self.transformer(x, x, src_key_padding_mask = mask)\n",
    "\n",
    "        x = self.fc(x[:, 0, :])\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(\n",
    "        model: torch.nn.Module,\n",
    "        train_loader,\n",
    "        loss_fn: torch.nn.Module,\n",
    "        optimizer: torch.optim.Optimizer,\n",
    "        device: torch.device,\n",
    "):\n",
    "    \"\"\"\n",
    "    Train model for one epoch.\n",
    "\n",
    "    Args:\n",
    "        model: PyTorch model to train.\n",
    "        train_loader: PyTorch dataloader for training data.\n",
    "        loss_fn: PyTorch loss function.\n",
    "        optimizer: PyTorch optimizer.\n",
    "        device: PyTorch device to use for training.\n",
    "\n",
    "    Returns:\n",
    "        Average loss, accuracy, macro F1 score, and macro recall for the epoch.\n",
    "    \"\"\"\n",
    "\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "\n",
    "    targets = []\n",
    "    predictions = []\n",
    "\n",
    "    for i, (_, emb, mask, target) in enumerate(tqdm(train_loader)):\n",
    "        target = target.float()\n",
    "        emb, mask, target = emb.to(device), mask.to(device), target.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(emb, mask)     \n",
    "        output = output.squeeze() \n",
    "        \n",
    "        loss = loss_fn(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        prediction = torch.sigmoid(output) > 0.5\n",
    "\n",
    "        predictions.extend(prediction.cpu().numpy())\n",
    "        targets.extend(target.cpu().numpy())\n",
    "\n",
    "\n",
    "\n",
    "    train_loss /= len(train_loader)\n",
    "    train_acc = accuracy_score(targets, predictions)\n",
    "    train_macro_f1 = f1_score(targets, predictions, average='macro')\n",
    "    train_macro_recall = recall_score(targets, predictions, average='macro')\n",
    "\n",
    "    return train_loss, train_acc, train_macro_f1, train_macro_recall\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_step(\n",
    "        model: torch.nn.Module,\n",
    "        val_loader,\n",
    "        loss_fn: torch.nn.Module,\n",
    "        device: torch.device,\n",
    "):\n",
    "    \"\"\"\n",
    "    Evaluate model on val data.\n",
    "\n",
    "    Args:\n",
    "        model: PyTorch model to evaluate.\n",
    "        val_loader: PyTorch dataloader for val data.\n",
    "        loss_fn: PyTorch loss function.\n",
    "        device: PyTorch device to use for evaluation.\n",
    "\n",
    "    Returns:\n",
    "        Average loss, accuracy, macro F1 score, and macro recall for the validation set.\n",
    "    \"\"\"\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_targets = []\n",
    "    val_predictions = []\n",
    "\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (_, emb, mask, target) in enumerate(tqdm(val_loader)):\n",
    "            target = target.float()\n",
    "            emb, mask, target = emb.to(device), mask.to(device), target.to(device)\n",
    "            output = model(emb, mask)\n",
    "            \n",
    "            output = output.squeeze()\n",
    "            loss = loss_fn(output, target)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            prediction = torch.sigmoid(output) > 0.5\n",
    "\n",
    "\n",
    "            val_predictions.extend(prediction.cpu().numpy())\n",
    "            val_targets.extend(target.cpu().numpy())\n",
    "        \n",
    "        val_loss /= len(val_loader)\n",
    "        val_acc = accuracy_score(val_targets, val_predictions)\n",
    "        val_macro_f1 = f1_score(val_targets, val_predictions, average='macro')\n",
    "        val_macro_recall = recall_score(val_targets, val_predictions, average='macro')\n",
    "\n",
    "\n",
    "\n",
    "    return val_loss, val_acc, val_macro_f1, val_macro_recall\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainer(\n",
    "        model: torch.nn.Module,\n",
    "        train_loader,\n",
    "        val_loader,\n",
    "        loss_fn: torch.nn.Module,\n",
    "        optimizer: torch.optim.Optimizer,\n",
    "        lr_scheduler: torch.optim.lr_scheduler,\n",
    "        lr_scheduler_name: str,\n",
    "        device: torch.device,\n",
    "        epochs: int,\n",
    "        save_dir: str,\n",
    "        early_stopper=None,\n",
    "        start_epoch = 1,\n",
    "):\n",
    "    \"\"\"\n",
    "    Train and evaluate model.\n",
    "\n",
    "    Args:\n",
    "        model: PyTorch model to train.\n",
    "        train_loader: PyTorch dataloader for training data.\n",
    "        val_loader: PyTorch dataloader for val data.\n",
    "        loss_fn: PyTorch loss function.\n",
    "        optimizer: PyTorch optimizer.\n",
    "        lr_scheduler: PyTorch learning rate scheduler.\n",
    "        device: PyTorch device to use for training.\n",
    "        epochs: Number of epochs to train the model for.\n",
    "\n",
    "    Returns:\n",
    "        Average loss and accuracy for the val set.\n",
    "    \"\"\"\n",
    "\n",
    "    results = {\n",
    "        \"train_loss\": [],\n",
    "        \"val_loss\": [],\n",
    "        \"train_acc\": [],\n",
    "        \"val_acc\": [],\n",
    "        \"train_f1\":[],\n",
    "        \"val_f1\":[],\n",
    "        \"train_recall\":[],\n",
    "        \"val_recall\":[],\n",
    "    }\n",
    "    best_val_loss = 1e10\n",
    "\n",
    "    for epoch in range(start_epoch, epochs + 1):\n",
    "\n",
    "        print(f\"Epoch {epoch}:\")\n",
    "        train_loss, train_acc, train_macro_f1, train_macro_recall = train_step(model, train_loader, loss_fn, optimizer, device)\n",
    "        print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, Train F1: {train_macro_f1:.4f}, Train recall: {train_macro_recall:.4f}\")\n",
    "\n",
    "        \n",
    "\n",
    "        results[\"train_loss\"].append(train_loss)\n",
    "        results[\"train_acc\"].append(train_acc)\n",
    "        results[\"train_f1\"].append(train_macro_f1)\n",
    "        results[\"train_recall\"].append(train_macro_recall)\n",
    "\n",
    "\n",
    "        val_loss, val_acc, val_f1, val_recall = val_step(model, val_loader, loss_fn, device)\n",
    "        print(f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}, Val F1: {val_f1:.4f}, Val recall: {val_recall:.4f}\")\n",
    "        print()\n",
    "\n",
    "        if lr_scheduler_name == \"ReduceLROnPlateau\":\n",
    "            lr_scheduler.step(val_loss)\n",
    "        elif lr_scheduler_name != \"None\":\n",
    "            lr_scheduler.step()\n",
    "        \n",
    "        results[\"val_loss\"].append(val_loss)\n",
    "        results[\"val_acc\"].append(val_acc)\n",
    "        results[\"val_f1\"].append(val_f1)\n",
    "        results[\"val_recall\"].append(val_recall)\n",
    "  \n",
    "        \n",
    "        \n",
    "        # wandb.log({\"train_loss\": train_loss, \"val_loss\": val_loss, \"train_acc\": train_acc, \"val_acc\": val_acc, \"train_f1\": train_macro_f1, \"train_recall\": train_macro_recall, \"val_f1\": val_f1, \"val_recall\": val_recall,  \"train_kappa\": train_kappa, \"val_kappa\": val_kappa, \"trian_auc\": train_auc, \"val_auc\": val_auc})\n",
    "        \n",
    "\n",
    "        checkpoint = { \n",
    "                'epoch': epoch,\n",
    "                'model': model.state_dict(),\n",
    "                'optimizer': optimizer.state_dict(),\n",
    "                'lr_sched': lr_scheduler}\n",
    "            \n",
    "                    \n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(checkpoint, os.path.join(save_dir, \"best_checkpoint.pth\"))\n",
    "\n",
    "        torch.save(checkpoint, os.path.join(save_dir, \"last_checkpoint.pth\"))\n",
    "\n",
    "        if early_stopper is not None:\n",
    "            if early_stopper.early_stop(val_loss):\n",
    "                print(\"Early stopping\")\n",
    "                break\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def START_seed(seed_value=9):\n",
    "    seed = seed_value\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda:0 device\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 1e-4\n",
    "NUM_EPOCHS = 2\n",
    "LEARNING_SCHEDULER = 'CosineAnnealingLR'\n",
    "LOSS = 'BCEWithLogitsLoss'\n",
    "SAVE_DIR = \"/home/nuren.zhaksylyk/Documents/HC701/project/PEFormer/runs\"\n",
    "DEVICE = torch.device(f\"cuda:0\" if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(f\"Using {DEVICE} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset_train, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(dataset_val, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = torch.utils.data.DataLoader(dataset_test, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.0000e-04.\n"
     ]
    }
   ],
   "source": [
    "START_seed()\n",
    "run_id = time.strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "if not os.path.exists(SAVE_DIR):\n",
    "    os.makedirs(SAVE_DIR)\n",
    "\n",
    "os.mkdir(SAVE_DIR + run_id)\n",
    "\n",
    "save_dir = SAVE_DIR + run_id\n",
    "\n",
    "model = PEFormer()\n",
    "model.to(DEVICE)\n",
    "\n",
    "torch.compile(model)\n",
    "\n",
    "if LOSS == \"MSE\":\n",
    "    loss = torch.nn.MSELoss()\n",
    "elif LOSS == \"L1Loss\":\n",
    "    loss = torch.nn.L1Loss()\n",
    "elif LOSS == \"SmoothL1Loss\":\n",
    "    loss = torch.nn.SmoothL1Loss()\n",
    "elif LOSS == \"CrossEntropyLoss\":\n",
    "    loss = torch.nn.CrossEntropyLoss()\n",
    "elif LOSS == \"BCEWithLogitsLoss\":\n",
    "    loss = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "if LEARNING_SCHEDULER == \"CosineAnnealingLR\":\n",
    "    lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=NUM_EPOCHS, verbose=True)\n",
    "elif LEARNING_SCHEDULER == \"ReduceLROnPlateau\":\n",
    "    lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=3, verbose=True)\n",
    "elif LEARNING_SCHEDULER == \"StepLR\":\n",
    "    lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1, verbose=True)\n",
    "elif LEARNING_SCHEDULER == \"MultiStepLR\":\n",
    "    lr_scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[15, 20], gamma=0.1)\n",
    "else:\n",
    "    lr_scheduler = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46/46 [00:51<00:00,  1.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.8903, Train Acc: 0.6018, Train F1: 0.4611, Train recall: 0.4926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/7 [00:00<?, ?it/s]/home/nuren.zhaksylyk/.conda/envs/nunoodles_v2/lib/python3.9/site-packages/torch/nn/modules/transformer.py:287: UserWarning: The PyTorch API of nested tensors is in prototype stage and will change in the near future. (Triggered internally at ../aten/src/ATen/NestedTensorImpl.cpp:177.)\n",
      "  output = torch._nested_tensor_from_mask(output, src_key_padding_mask.logical_not(), mask_check=False)\n",
      " 86%|████████▌ | 6/7 [00:01<00:00,  4.00it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Target size (torch.Size([1])) must be the same as input size (torch.Size([]))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m results \u001b[39m=\u001b[39m trainer(\n\u001b[1;32m      2\u001b[0m         model\u001b[39m=\u001b[39;49mmodel,\n\u001b[1;32m      3\u001b[0m         train_loader\u001b[39m=\u001b[39;49mtrain_loader,\n\u001b[1;32m      4\u001b[0m         val_loader\u001b[39m=\u001b[39;49mval_loader,\n\u001b[1;32m      5\u001b[0m         loss_fn\u001b[39m=\u001b[39;49mloss,\n\u001b[1;32m      6\u001b[0m         optimizer\u001b[39m=\u001b[39;49moptimizer,\n\u001b[1;32m      7\u001b[0m         lr_scheduler\u001b[39m=\u001b[39;49mlr_scheduler,\n\u001b[1;32m      8\u001b[0m         lr_scheduler_name\u001b[39m=\u001b[39;49mLEARNING_SCHEDULER,\n\u001b[1;32m      9\u001b[0m         device\u001b[39m=\u001b[39;49mDEVICE,\n\u001b[1;32m     10\u001b[0m         epochs\u001b[39m=\u001b[39;49mNUM_EPOCHS,\n\u001b[1;32m     11\u001b[0m         save_dir\u001b[39m=\u001b[39;49msave_dir,\n\u001b[1;32m     12\u001b[0m         early_stopper\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m     13\u001b[0m     )\n",
      "Cell \u001b[0;32mIn[8], line 58\u001b[0m, in \u001b[0;36mtrainer\u001b[0;34m(model, train_loader, val_loader, loss_fn, optimizer, lr_scheduler, lr_scheduler_name, device, epochs, save_dir, early_stopper, start_epoch)\u001b[0m\n\u001b[1;32m     54\u001b[0m results[\u001b[39m\"\u001b[39m\u001b[39mtrain_f1\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mappend(train_macro_f1)\n\u001b[1;32m     55\u001b[0m results[\u001b[39m\"\u001b[39m\u001b[39mtrain_recall\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mappend(train_macro_recall)\n\u001b[0;32m---> 58\u001b[0m val_loss, val_acc, val_f1, val_recall \u001b[39m=\u001b[39m val_step(model, val_loader, loss_fn, device)\n\u001b[1;32m     59\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mVal Loss: \u001b[39m\u001b[39m{\u001b[39;00mval_loss\u001b[39m:\u001b[39;00m\u001b[39m.4f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m, Val Acc: \u001b[39m\u001b[39m{\u001b[39;00mval_acc\u001b[39m:\u001b[39;00m\u001b[39m.4f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m, Val F1: \u001b[39m\u001b[39m{\u001b[39;00mval_f1\u001b[39m:\u001b[39;00m\u001b[39m.4f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m, Val recall: \u001b[39m\u001b[39m{\u001b[39;00mval_recall\u001b[39m:\u001b[39;00m\u001b[39m.4f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     60\u001b[0m \u001b[39mprint\u001b[39m()\n",
      "Cell \u001b[0;32mIn[7], line 32\u001b[0m, in \u001b[0;36mval_step\u001b[0;34m(model, val_loader, loss_fn, device)\u001b[0m\n\u001b[1;32m     30\u001b[0m output \u001b[39m=\u001b[39m model(emb, mask)\n\u001b[1;32m     31\u001b[0m output \u001b[39m=\u001b[39m output\u001b[39m.\u001b[39msqueeze()\n\u001b[0;32m---> 32\u001b[0m loss \u001b[39m=\u001b[39m loss_fn(output, target)\n\u001b[1;32m     33\u001b[0m val_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mitem()\n\u001b[1;32m     35\u001b[0m prediction \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39msigmoid(output) \u001b[39m>\u001b[39m \u001b[39m0.5\u001b[39m\n",
      "File \u001b[0;32m~/.conda/envs/nunoodles_v2/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.conda/envs/nunoodles_v2/lib/python3.9/site-packages/torch/nn/modules/loss.py:720\u001b[0m, in \u001b[0;36mBCEWithLogitsLoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    719\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor, target: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 720\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mbinary_cross_entropy_with_logits(\u001b[39minput\u001b[39;49m, target,\n\u001b[1;32m    721\u001b[0m                                               \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight,\n\u001b[1;32m    722\u001b[0m                                               pos_weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpos_weight,\n\u001b[1;32m    723\u001b[0m                                               reduction\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreduction)\n",
      "File \u001b[0;32m~/.conda/envs/nunoodles_v2/lib/python3.9/site-packages/torch/nn/functional.py:3163\u001b[0m, in \u001b[0;36mbinary_cross_entropy_with_logits\u001b[0;34m(input, target, weight, size_average, reduce, reduction, pos_weight)\u001b[0m\n\u001b[1;32m   3160\u001b[0m     reduction_enum \u001b[39m=\u001b[39m _Reduction\u001b[39m.\u001b[39mget_enum(reduction)\n\u001b[1;32m   3162\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (target\u001b[39m.\u001b[39msize() \u001b[39m==\u001b[39m \u001b[39minput\u001b[39m\u001b[39m.\u001b[39msize()):\n\u001b[0;32m-> 3163\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mTarget size (\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m) must be the same as input size (\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(target\u001b[39m.\u001b[39msize(), \u001b[39minput\u001b[39m\u001b[39m.\u001b[39msize()))\n\u001b[1;32m   3165\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39mbinary_cross_entropy_with_logits(\u001b[39minput\u001b[39m, target, weight, pos_weight, reduction_enum)\n",
      "\u001b[0;31mValueError\u001b[0m: Target size (torch.Size([1])) must be the same as input size (torch.Size([]))"
     ]
    }
   ],
   "source": [
    "results = trainer(\n",
    "        model=model,\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "        loss_fn=loss,\n",
    "        optimizer=optimizer,\n",
    "        lr_scheduler=lr_scheduler,\n",
    "        lr_scheduler_name=LEARNING_SCHEDULER,\n",
    "        device=DEVICE,\n",
    "        epochs=NUM_EPOCHS,\n",
    "        save_dir=save_dir,\n",
    "        early_stopper=None,\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nunoodles_v2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
