{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pk = \"/home/nuren.zhaksylyk/Documents/HC701/project/PEFormer/out_embeds_train.pickle\"\n",
    "test_pk = \"/home/nuren.zhaksylyk/Documents/HC701/project/PEFormer/out_embeds_test.pickle\"\n",
    "val_pk = \"/home/nuren.zhaksylyk/Documents/HC701/project/PEFormer/out_embeds_val.pickle\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load pickles\n",
    "with open(train_pk, 'rb') as f:\n",
    "    train_data = pickle.load(f)\n",
    "\n",
    "with open(test_pk, 'rb') as f:\n",
    "    test_data = pickle.load(f)\n",
    "\n",
    "with open(val_pk, 'rb') as f:\n",
    "    val_data = pickle.load(f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24548, 3224, 3222)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data), len(test_data), len(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "for patient in test_data.keys():\n",
    "    train_data[patient] = test_data[patient]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "for patient in val_data.keys():\n",
    "    train_data[patient] = val_data[patient]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save train data in to ct_out_embeds.pickle\n",
    "with open(\"/home/nuren.zhaksylyk/Documents/HC701/project/PEFormer/data/ct/all_ct_out_embeds.pickle\", 'wb') as f:\n",
    "    pickle.dump(train_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv_path = \"/home/nuren.zhaksylyk/Documents/HC701/project/PEFormer/labels_train.csv\"\n",
    "test_csv_path = \"/home/nuren.zhaksylyk/Documents/HC701/project/PEFormer/labels_test.csv\"\n",
    "val_csv_path = \"/home/nuren.zhaksylyk/Documents/HC701/project/PEFormer/labels_val.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load csvs and concatenate them\n",
    "train_csv = pd.read_csv(train_csv_path)\n",
    "test_csv = pd.read_csv(test_csv_path)\n",
    "val_csv = pd.read_csv(val_csv_path)\n",
    "\n",
    "train_csv = pd.concat([train_csv, test_csv, val_csv], axis=0)\n",
    "\n",
    "#update index\n",
    "train_csv.reset_index(drop=True, inplace=True)\n",
    "\n",
    "#save updated csv\n",
    "train_csv.to_csv(\"/home/nuren.zhaksylyk/Documents/HC701/project/PEFormer/data/ct/ct_labels.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits_csv = \"/home/nuren.zhaksylyk/Documents/HC701/project/PEFormer/data/Labels.csv\"\n",
    "splits = pd.read_csv(splits_csv)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>target</th>\n",
       "      <th>pe_type</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1436</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1880</td>\n",
       "      <td>1</td>\n",
       "      <td>segmental</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2738</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2883</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2302</td>\n",
       "      <td>1</td>\n",
       "      <td>segmental</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    idx  target    pe_type  split\n",
       "0  1436       0        NaN  train\n",
       "1  1880       1  segmental  train\n",
       "2  2738       0        NaN    val\n",
       "3  2883       0        NaN  train\n",
       "4  2302       1  segmental  train"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splits = splits[['idx', 'label', 'pe_type', 'split']]\n",
    "splits.rename(columns={'label': 'target'}, inplace=True)\n",
    "splits.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>study_num</th>\n",
       "      <th>slice_idx</th>\n",
       "      <th>label</th>\n",
       "      <th>target</th>\n",
       "      <th>pe_type</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1436</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1436</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1436</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1436</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1436</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   study_num  slice_idx  label  target pe_type  split\n",
       "0       1436          0      0       0     NaN  train\n",
       "1       1436         24      0       0     NaN  train\n",
       "2       1436         48      0       0     NaN  train\n",
       "3       1436         72      0       0     NaN  train\n",
       "4       1436         96      0       0     NaN  train"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df = pd.merge(train_csv, splits, left_on='study_num', right_on='idx', how='left')\n",
    "merged_df.drop('idx', axis=1, inplace=True)\n",
    "\n",
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.to_csv(\"/home/nuren.zhaksylyk/Documents/HC701/project/PEFormer/data/ct/all_ct_labels_split.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       study_num  slice_idx  label  target    pe_type  split\n",
      "11320        291          0      0       1  segmental  train\n",
      "11321        291         24      0       1  segmental  train\n",
      "11322        291         48      0       1  segmental  train\n",
      "11323        291         72      1       1  segmental  train\n",
      "11324        291         96      0       1  segmental  train\n",
      "...          ...        ...    ...     ...        ...    ...\n",
      "11424        291       2496      0       1  segmental  train\n",
      "11425        291       2520      0       1  segmental  train\n",
      "11426        291       2544      0       1  segmental  train\n",
      "11427        291       2568      0       1  segmental  train\n",
      "11428        291       2592      0       1  segmental  train\n",
      "\n",
      "[109 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "merged = pd.read_csv(\"/home/nuren.zhaksylyk/Documents/HC701/project/PEFormer/data/ct/ct_labels_split.csv\")\n",
    "\n",
    "merged_450 = merged[merged['study_num']==291]\n",
    "#print all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from torch.utils.data import Dataset\n",
    "import pickle\n",
    "import torch\n",
    "\n",
    "class UltrasonicDataset(Dataset):\n",
    "    def __init__(self, pkl_file, csv_file, split, transform=None):\n",
    "        with open(pkl_file, 'rb') as f:\n",
    "            self.pkl = pickle.load(f)\n",
    "\n",
    "        self.csv = pd.read_csv(csv_file)\n",
    "        #sort by study_num\n",
    "        self.csv = self.csv.sort_values(by=['study_num', 'slice_idx'])\n",
    "        self.transform = transform\n",
    "        self.split = split\n",
    "        self.study_num = []\n",
    "        self.data = []\n",
    "        cur_id = -1\n",
    "        for i in range(len(self.csv)):\n",
    "            if self.csv['split'][i] != self.split:\n",
    "                continue\n",
    "            if i == 0 or self.csv['study_num'][i] != self.csv['study_num'][i-1]:\n",
    "                self.study_num.append(self.csv['study_num'][i])\n",
    "                cur_id += 1\n",
    "                self.data.append({\"embeddings\": [self.pkl[f\"{self.csv['study_num'][i]}_{self.csv['slice_idx'][i]}\"]], \"label\": self.csv['target'][i]})\n",
    "\n",
    "            else:\n",
    "                self.data[cur_id][\"embeddings\"].append(self.pkl[f\"{self.csv['study_num'][i]}_{self.csv['slice_idx'][i]}\"])\n",
    "        \n",
    "        print(f\"Loaded {len(self.data)} samples\")\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        target = int(self.data[idx][\"label\"])\n",
    "        embeddings = self.data[idx][\"embeddings\"]\n",
    "        embeddings = torch.stack(embeddings, dim=0)\n",
    "\n",
    "        study_num = self.study_num[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            embeddings = self.transform(embeddings)\n",
    "        \n",
    "        return study_num, embeddings, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1454 samples\n"
     ]
    }
   ],
   "source": [
    "dataset = UltrasonicDataset(pkl_file=\"/home/nuren.zhaksylyk/Documents/HC701/project/PEFormer/data/ct/all_ct_out_embeds.pickle\", csv_file=\"/home/nuren.zhaksylyk/Documents/HC701/project/PEFormer/data/ct/all_ct_labels_split.csv\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 193 samples\n"
     ]
    }
   ],
   "source": [
    "dataset_val = UltrasonicDataset(pkl_file=\"/home/nuren.zhaksylyk/Documents/HC701/project/PEFormer/data/ct/all_ct_out_embeds.pickle\", csv_file=\"/home/nuren.zhaksylyk/Documents/HC701/project/PEFormer/data/ct/all_ct_labels_split.csv\", split=\"val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 190 samples\n"
     ]
    }
   ],
   "source": [
    "dataset_test = UltrasonicDataset(pkl_file=\"/home/nuren.zhaksylyk/Documents/HC701/project/PEFormer/data/ct/all_ct_out_embeds.pickle\", csv_file=\"/home/nuren.zhaksylyk/Documents/HC701/project/PEFormer/data/ct/all_ct_labels_split.csv\", split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2956"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df['study_num'][100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1429, 162, 164)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_csv = pd.read_csv(train_csv_path)\n",
    "test_csv = pd.read_csv(test_csv_path)\n",
    "val_csv = pd.read_csv(val_csv_path)\n",
    "\n",
    "len(train_csv['study_num'].unique()), len(test_csv['study_num'].unique()), len(val_csv['study_num'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2506:torch.Size([20, 2048])\n",
      "2832:torch.Size([21, 2048])\n",
      "15:torch.Size([23, 2048])\n",
      "1222:torch.Size([24, 2048])\n",
      "2465:torch.Size([26, 2048])\n",
      "2387:torch.Size([34, 2048])\n",
      "306:torch.Size([36, 2048])\n",
      "36 2.217331499312242\n"
     ]
    }
   ],
   "source": [
    "max = 0\n",
    "\n",
    "sum = 0\n",
    "\n",
    "for study_num, emb, target in dataset_test:\n",
    "    \n",
    "    if emb.shape[0] > max:\n",
    "        max = emb.shape[0]\n",
    "        print(f\"{study_num}:{emb.shape}\")\n",
    "    sum += emb.shape[0]\n",
    "\n",
    "print(max, sum/len(dataset))\n",
    "\n",
    "#109 maximum number of slices in a single"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nunoodles_v2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
